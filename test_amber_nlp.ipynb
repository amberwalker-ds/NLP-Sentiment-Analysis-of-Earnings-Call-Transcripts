{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Change this to a directory that's not the NumPy source directory\n",
    "#load libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lxml import html\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from wordcloud import WordCloud  # Import wordcloud package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths\n",
    "download_folder = './downloads'\n",
    "gecko_driver_path = '/Users/amberwalker/Intro_text_nlp/ps1/geckodriver'\n",
    "profile_path =  '/Users/amberwalker/Library/Application Support/Firefox/Profiles/9eq5v9xc.default-release-1'\n",
    "link = 'https://www.fool.com/quote/nyse/rcl/'\n",
    "file_path_out ='output.csv'\n",
    "file_path = '/Users/amberwalker/Intro_text_nlp/final_project/final_texts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_firefox_preferences(download_folder, profile_path, enable_download=False):\n",
    "    \"\"\"\n",
    "    Configures Firefox preferences for Selenium WebDriver.\n",
    "    \"\"\"\n",
    "    # Use the provided profile path\n",
    "    profile = webdriver.FirefoxProfile(profile_path)\n",
    "\n",
    "    # Set preferences\n",
    "    profile.set_preference(\"browser.download.dir\", download_folder)\n",
    "    profile.set_preference(\"browser.download.folderList\", 2)\n",
    "    profile.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "    profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\",\n",
    "                           \"application/msword,application/rtf,application/csv,text/csv,image/png,image/jpeg,application/pdf,text/html,text/plain,application/octet-stream\")\n",
    "\n",
    "    # Automatically download PDFs\n",
    "    if enable_download:\n",
    "        profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/x-pdf\")\n",
    "        profile.set_preference(\"pdfjs.disabled\", True)\n",
    "\n",
    "    options = Options()\n",
    "    options.profile = profile\n",
    "    return options\n",
    "\n",
    "def start_firefox(link, download_folder, gecko_driver_path, profile_path, enable_download=True):\n",
    "    \"\"\"\n",
    "    Initializes a Firefox WebDriver session.\n",
    "    \"\"\"\n",
    "    # Explicitly specify the path to the Firefox executable\n",
    "    options = Options()\n",
    "    options.binary_location = r\"C:\\Program Files\\Mozilla Firefox\\firefox.exe\"\n",
    "\n",
    "    # Ensure the download folder exists\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    # Set Firefox preferences with the given profile\n",
    "    options = set_firefox_preferences(download_folder, profile_path, enable_download)\n",
    "\n",
    "    # Set up the service with the path to the geckodriver\n",
    "    service = Service(executable_path=gecko_driver_path)\n",
    "    browser = webdriver.Firefox(options=options, service=service)\n",
    "    browser.get(link)\n",
    "    time.sleep(5)  # Adjust sleep time as needed\n",
    "    return browser\n",
    "\n",
    "def perform_click_action(browser, xpath, click_type):\n",
    "    \"\"\"\n",
    "    Tries to click on an element. If obscured, waits and retries.\n",
    "    \"\"\"\n",
    "    attempt_count = 0\n",
    "    while attempt_count < 15:\n",
    "        if try_click_element(browser, xpath, click_type):\n",
    "            return\n",
    "        time.sleep(1)\n",
    "        attempt_count += 1\n",
    "    # Optional: Add warning sound or logging here if needed\n",
    "\n",
    "def try_click_element(browser, xpath, click_type):\n",
    "    \"\"\"\n",
    "    Attempts to click an element based on its type.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        element = {\n",
    "            \"xpath\": lambda: browser.find_element_by_xpath(xpath),\n",
    "            \"id\": lambda: browser.find_element_by_id(xpath),\n",
    "            \"css\": lambda: browser.find_element_by_css_selector(xpath),\n",
    "            \"class\": lambda: browser.find_element_by_class_name(xpath),\n",
    "            \"link\": lambda: browser.find_element_by_link_text(xpath)\n",
    "        }.get(click_type, lambda: None)()\n",
    "\n",
    "        if element:\n",
    "            element.click()\n",
    "            return True\n",
    "    except (ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "    return False\n",
    "\n",
    "# Function that collects the link to then later open them \n",
    "def collect_transcript_links(browser):\n",
    "    links = []\n",
    "    try:\n",
    "        # Initially collect available links before clicking \"View More\"\n",
    "        transcript_elements = browser.find_elements(By.CSS_SELECTOR, 'a[data-track-category=\"quotepage_transcripts\"]')\n",
    "        links.extend([element.get_attribute('href') for element in transcript_elements])\n",
    "        \n",
    "        while True:\n",
    "            # Try to click \"View More\" button to load more transcripts\n",
    "            #view_more_button = browser.find_element(By.XPATH, \"//span[contains(text(), 'View More RCL Earnings Transcripts')]\")\n",
    "            view_more_button = browser.find_element(By.XPATH, \"//span[contains(text(), 'View More') and contains(text(), 'Earnings Transcripts')]\")\n",
    "\n",
    "            browser.execute_script(\"arguments[0].click();\", view_more_button)\n",
    "            time.sleep(2)  # Adjust based on actual page load time\n",
    "            \n",
    "            # Update the list of transcript elements after loading more\n",
    "            new_transcript_elements = browser.find_elements(By.CSS_SELECTOR, 'a[data-track-category=\"quotepage_transcripts\"]')\n",
    "            new_links = [element.get_attribute('href') for element in new_transcript_elements]\n",
    "            \n",
    "            # Check if new links were added after clicking \"View More\"\n",
    "            if len(new_links) > len(links):\n",
    "                print(f\"Collected {len(new_links) - len(links)} new links. Total collected: {len(new_links)}\")\n",
    "                links = new_links  # Update the links list with the new set of links\n",
    "            else:\n",
    "                # No new links were added indicating all links have been loaded or \"View More\" is not working as expected\n",
    "                print(\"No new links collected. Assuming all links have been collected.\")\n",
    "                break\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle cases where \"View More\" button is not found or other errors occur\n",
    "        print(\"No more 'View More' button found or an error occurred:\", str(e))\n",
    "    \n",
    "    return links\n",
    "\n",
    "#function to scrape ALL text from each link (webpage)\n",
    "def scrape_all_text(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    \n",
    "    try:\n",
    "        # Wait for the page to load\n",
    "        WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        # Scrape all text\n",
    "        all_text = browser.find_element(By.TAG_NAME, \"body\").text\n",
    "        return all_text\n",
    "    finally:\n",
    "        browser.quit()\n",
    "        \n",
    "def extract_executive_speeches_from_text(text, ceo_info, cfo_info):\n",
    "    speeches = {'CEO': [], 'CFO': [], 'Title': '', 'Date': ''}\n",
    "    current_executive = None\n",
    "    speech_lines = []\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Search for title and date in the text\n",
    "    for line in lines:\n",
    "        title_pattern = re.compile(r'(.*?)\\s+\\((.*?)\\)\\s+(Q[1-4]\\s+\\d{4})\\s+Earnings Call Transcript')\n",
    "        date_pattern = re.compile(r'period ending (\\w+ \\d{1,2}, \\d{4})')\n",
    "        title_match = title_pattern.search(line)\n",
    "        date_match = date_pattern.search(line)\n",
    "        if title_match:\n",
    "            speeches['Title'] = title_match.group(0)  # The entire match\n",
    "        if date_match:\n",
    "            speeches['Date'] = date_match.group(1)\n",
    "\n",
    "    for line in lines:\n",
    "        if any(name in line for name in ceo_info['names']) or any(keyword in line for keyword in ceo_info['keywords']):\n",
    "            if speech_lines and current_executive:\n",
    "                speeches[current_executive].append(' '.join(speech_lines))\n",
    "                speech_lines = []\n",
    "            current_executive = 'CEO'\n",
    "        elif any(name in line for name in cfo_info['names']) or any(keyword in line for keyword in cfo_info['keywords']):\n",
    "            if speech_lines and current_executive:\n",
    "                speeches[current_executive].append(' '.join(speech_lines))\n",
    "                speech_lines = []\n",
    "            current_executive = 'CFO'\n",
    "\n",
    "        if current_executive:\n",
    "            speech_lines.append(line.strip())\n",
    "            \n",
    "            # Heuristic to detect potential end of speech\n",
    "            if \"--\" in line:\n",
    "                speeches[current_executive].append(' '.join(speech_lines))\n",
    "                speech_lines = []\n",
    "                current_executive = None\n",
    "\n",
    "    # Ensure the last captured speech is saved\n",
    "    if speech_lines and current_executive:\n",
    "        speeches[current_executive].append(' '.join(speech_lines))\n",
    "\n",
    "    return speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 4 new links. Total collected: 8\n",
      "Collected 4 new links. Total collected: 12\n",
      "Collected 4 new links. Total collected: 16\n",
      "Collected 4 new links. Total collected: 20\n",
      "Collected 2 new links. Total collected: 22\n",
      "No new links collected. Assuming all links have been collected.\n",
      "Collected 4 new links. Total collected: 8\n",
      "Collected 4 new links. Total collected: 12\n",
      "Collected 4 new links. Total collected: 16\n",
      "Collected 4 new links. Total collected: 20\n",
      "No new links collected. Assuming all links have been collected.\n",
      "Collected 4 new links. Total collected: 8\n",
      "Collected 4 new links. Total collected: 12\n",
      "Collected 4 new links. Total collected: 16\n",
      "Collected 3 new links. Total collected: 19\n",
      "No new links collected. Assuming all links have been collected.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Collect Transcript Links\n",
    "companies = [\n",
    "    {'symbol': 'RCL', 'url': 'https://www.fool.com/quote/nyse/rcl/'},\n",
    "    {'symbol': 'CCL', 'url': 'https://www.fool.com/quote/nyse/ccl/'},\n",
    "    {'symbol': 'NCLH', 'url': 'https://www.fool.com/quote/nyse/nclh/'}\n",
    "]\n",
    "\n",
    "transcript_link_by_company = {} #dictionary to store company info\n",
    "\n",
    "for company in companies:\n",
    "    # Extract company-specific information\n",
    "    symbol = company['symbol']\n",
    "    company_url = company['url']\n",
    "    \n",
    "    # Start up the browser for each company's URL\n",
    "    browser = start_firefox(company_url, download_folder, gecko_driver_path, profile_path)\n",
    "    \n",
    "    # Collect transcript links for the current company\n",
    "    company_transcript_links = collect_transcript_links(browser)\n",
    "    \n",
    "    # Store the links in the dictionary under the current company's symbol\n",
    "    transcript_link_by_company[symbol] = company_transcript_links\n",
    "    \n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store each company's DataFrame\n",
    "company_dataframes = {}\n",
    "\n",
    "for symbol, links in transcript_link_by_company.items():\n",
    "    company_texts = []\n",
    "\n",
    "    for link in links:\n",
    "        scraped_text = scrape_all_text(link)\n",
    "        company_texts.append({\n",
    "            'Link': link,\n",
    "            'Text': scraped_text\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame for the current company's texts\n",
    "    df = pd.DataFrame(company_texts)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary using the company symbol as the key\n",
    "    company_dataframes[symbol] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Link  \\\n",
      "0  https://www.fool.com/earnings/call-transcripts...   \n",
      "1  https://www.fool.com/earnings/call-transcripts...   \n",
      "2  https://www.fool.com/earnings/call-transcripts...   \n",
      "3  https://www.fool.com/earnings/call-transcripts...   \n",
      "4  https://www.fool.com/earnings/call-transcripts...   \n",
      "\n",
      "                                               Title               Date  \\\n",
      "0  Norwegian Cruise Line (NCLH) Q4 2023 Earnings ...  December 31, 2023   \n",
      "1  Norwegian Cruise Line (NCLH) Q4 2023 Earnings ...  December 31, 2023   \n",
      "2  Norwegian Cruise Line (NCLH) Q4 2023 Earnings ...  December 31, 2023   \n",
      "3  Norwegian Cruise Line (NCLH) Q4 2023 Earnings ...  December 31, 2023   \n",
      "4  Norwegian Cruise Line (NCLH) Q4 2023 Earnings ...  December 31, 2023   \n",
      "\n",
      "  Executive                                             Speech  \n",
      "0       CEO  Thank you, Donna, and good morning, everyone. ...  \n",
      "1       CEO  With that, I'd like to call -- turn the call o...  \n",
      "2       CEO  Harry Sommer -- President and Chief Executive ...  \n",
      "3       CEO  Mark Kempa -- Executive Vice President, Chief ...  \n",
      "4       CEO  Harry Sommer -- President and Chief Executive ...  \n"
     ]
    }
   ],
   "source": [
    "#looking for keywords and titles to identify whether it's CEO or CFO\n",
    "ceo_info = {\n",
    "    'names': [\"ArnoldDonald\", \"Frank J. Del Rio\", \"Josh Weinstein\", \"Arnold Donald\", \"Frank Del Rio\", \"Michael Bayley\", \"Harry Sommer\"],\n",
    "    'keywords': [\"President and Chief Executive Officer, Norwegian Cruise Line Holdings\", \"Chief Executive Officer\", \"CEO\", \"President\", \"President and Chief Executive Officer\", \"President & Chief Executive Officer\"]\n",
    "}\n",
    "\n",
    "cfo_info = {\n",
    "    'names': [\"Mark A. Kempa\", \"Mark Kempa\", \"Jason Liberty\", \"Naftali Holtz\", \"David Bernstein\"],\n",
    "    'keywords': [\"Executive Vice President & Chief Financial Officer\", \"Executive Vice President, Chief Financial Officer\", \"Chief Financial Officer\", \"CFO\", \"Executive Vice President, Chief Financial Officer\", \"Chief Financial Officer and Chief Accounting Officer\", \"Executive Vice President and Chief Financial Officer\"]\n",
    "}\n",
    "\n",
    "#loop to iterate through DataFrame rows\n",
    "results = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    url = row['Link']\n",
    "    text = row['Text']\n",
    "    \n",
    "    speeches_info = extract_executive_speeches_from_text(text, ceo_info, cfo_info)\n",
    "    \n",
    "    title = speeches_info.get('Title', 'Unknown Title')\n",
    "    date = speeches_info.get('Date', 'Unknown Date')\n",
    "    \n",
    "    for executive in ['CEO', 'CFO']:\n",
    "        for speech in speeches_info.get(executive, []):\n",
    "            results.append({\n",
    "                'Link': link,\n",
    "                'Title': title,\n",
    "                'Date': date,\n",
    "                'Executive': executive,\n",
    "                'Speech': speech\n",
    "            })\n",
    "\n",
    "# Convert the results list of dictionaries into a DataFrame\n",
    "final_texts = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(final_texts.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "final_texts.to_csv('final_texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2631 entries, 0 to 2630\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Link       2631 non-null   object\n",
      " 1   Title      2488 non-null   object\n",
      " 2   Date       2631 non-null   object\n",
      " 3   Executive  2631 non-null   object\n",
      " 4   Speech     2631 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 102.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv(file_path)\n",
    "\n",
    "print(final_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes were made.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'final_texts' is your DataFrame\n",
    "# Example keywords for demonstration\n",
    "cfo_keywords = [\n",
    "    \"Executive Vice President & Chief Financial Officer\",\n",
    "    \"Executive Vice President, Chief Financial Officer\",\n",
    "    \"Chief Financial Officer\",\n",
    "    \"CFO\",\n",
    "    \"Executive Vice President, Chief Financial Officer\",\n",
    "    \"Chief Financial Officer and Chief Accounting Officer\",\n",
    "    \"Executive Vice President and Chief Financial Officer\"\n",
    "]\n",
    "\n",
    "# Function to check if the speech starts with any CFO keyword\n",
    "def starts_with_cfo_keyword(speech, keywords):\n",
    "    for keyword in keywords:\n",
    "        if speech.startswith(keyword):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Initialize a list to keep track of rows where changes are made\n",
    "changed_rows = []\n",
    "\n",
    "# Iterate through the DataFrame and update the 'Executive' column\n",
    "for index, row in final_df.iterrows():\n",
    "    if row['Executive'] == 'CEO' and starts_with_cfo_keyword(row['Speech'], cfo_keywords):\n",
    "        final_df.at[index, 'Executive'] = 'CFO'\n",
    "        changed_rows.append(index)  # Add the index of the changed row to the list\n",
    "\n",
    "# Report changes\n",
    "if changed_rows:\n",
    "    print(f\"Changed the 'Executive' column for {len(changed_rows)} rows to 'CFO'.\")\n",
    "    for index in changed_rows:\n",
    "        print(f\"Row {index} was changed.\")\n",
    "else:\n",
    "    print(\"No changes were made.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
